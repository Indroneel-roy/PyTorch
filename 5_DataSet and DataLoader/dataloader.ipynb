{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ac88ad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n"
     ]
    }
   ],
   "source": [
    "print(\"hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62cd7d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46955441",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0  ...          17.33           184.60      2019.0            0.1622   \n",
       "1  ...          23.41           158.80      1956.0            0.1238   \n",
       "2  ...          25.53           152.50      1709.0            0.1444   \n",
       "3  ...          26.50            98.87       567.7            0.2098   \n",
       "4  ...          16.67           152.20      1575.0            0.1374   \n",
       "\n",
       "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "\n",
       "   fractal_dimension_worst  Unnamed: 32  \n",
       "0                  0.11890          NaN  \n",
       "1                  0.08902          NaN  \n",
       "2                  0.08758          NaN  \n",
       "3                  0.17300          NaN  \n",
       "4                  0.07678          NaN  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/gscdit/Breast-Cancer-Detection/refs/heads/master/data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95e7ba0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 33)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a42d208",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'diagnosis', 'radius_mean', 'texture_mean', 'perimeter_mean',\n",
       "       'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',\n",
       "       'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean',\n",
       "       'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',\n",
       "       'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se',\n",
       "       'fractal_dimension_se', 'radius_worst', 'texture_worst',\n",
       "       'perimeter_worst', 'area_worst', 'smoothness_worst',\n",
       "       'compactness_worst', 'concavity_worst', 'concave points_worst',\n",
       "       'symmetry_worst', 'fractal_dimension_worst', 'Unnamed: 32'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d5aece1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['id', 'Unnamed: 32'], inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b78cef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.iloc[:, 1:], df.iloc[:, 0], test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7be7aba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7732722f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.32195498, -1.16582351, -0.32517272, ..., -0.85807987,\n",
       "        -0.76071998,  0.90337207],\n",
       "       [-1.19999034,  0.00920603, -1.14664513, ..., -0.2664368 ,\n",
       "        -0.45131108,  0.03790348],\n",
       "       [-0.82103095,  0.11375411, -0.82058628, ..., -1.43894924,\n",
       "         0.63976239, -1.02662288],\n",
       "       ...,\n",
       "       [ 2.5258797 ,  0.10693575,  2.45061233, ...,  1.68967268,\n",
       "         0.01443073, -0.61822989],\n",
       "       [ 0.59442747, -0.13397939,  0.68361009, ...,  0.88240386,\n",
       "        -0.21029784,  1.19546772],\n",
       "       [ 0.15738353, -1.22264312,  0.25185758, ..., -0.06446785,\n",
       "        -0.11747517,  0.42628251]], shape=(455, 30))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e09bfd9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.13303921, -0.05215915, -0.10562371, ...,  0.38924151,\n",
       "        -0.252638  ,  0.22668382],\n",
       "       [-0.38116738, -0.65217423, -0.43576339, ..., -0.85322412,\n",
       "        -0.8405149 , -1.08720569],\n",
       "       [-1.19209535, -0.29534708, -1.12011969, ..., -0.24200629,\n",
       "        -0.46433882,  1.73097641],\n",
       "       ...,\n",
       "       [ 0.76360577,  0.02284273,  0.66728674, ..., -0.46567439,\n",
       "        -0.60601553, -1.32412771],\n",
       "       [-1.32405443, -0.23625469, -1.31518368, ..., -0.97917019,\n",
       "        -0.72489368, -0.15358144],\n",
       "       [-1.11709298, -1.01809252, -1.12216011, ..., -1.3544288 ,\n",
       "         1.07130638, -0.21632792]], shape=(114, 30))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "06de5f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "y_train = encoder.fit_transform(y_train)\n",
    "y_test = encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "65e8e2bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(455,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "86e1c71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Numpy array to Pytorch tensor\n",
    "X_train_tensor = torch.from_numpy(X_train.astype(np.float32))\n",
    "X_test_tensor = torch.from_numpy(X_test.astype(np.float32))\n",
    "y_train_tensor = torch.from_numpy(y_train.astype(np.float32))\n",
    "y_test_tensor = torch.from_numpy(y_test.astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fee8d4ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([455, 30])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5570fa8",
   "metadata": {},
   "source": [
    "# The Dataset and DataLoader Classes\n",
    "\n",
    "Dataset and DataLoader are core abstractions in PyTorch that decouple how you define your data from how you efficiently iterate over it in training loops.\n",
    "\n",
    "---\n",
    "\n",
    "## Dataset Class\n",
    "\n",
    "The Dataset class is essentially a **blueprint**. When you create a custom Dataset, you decide how data is loaded and returned.\n",
    "\n",
    "### Key Components\n",
    "\n",
    "The Dataset defines three essential methods:\n",
    "\n",
    "- **`__init__()`** → tells how data should be loaded\n",
    "- **`__len__()`** → returns the total number of samples\n",
    "- **`__getitem__(index)`** → returns the data (and label) at the given index\n",
    "\n",
    "### Characteristics\n",
    "\n",
    "The Dataset:\n",
    "- Reads data from memory or disk\n",
    "- Returns one sample at a time\n",
    "- Does not handle batching\n",
    "\n",
    "---\n",
    "\n",
    "## DataLoader Class\n",
    "\n",
    "The DataLoader wraps a Dataset and handles the heavy lifting of data iteration during training.\n",
    "\n",
    "### Key Responsibilities\n",
    "\n",
    "The DataLoader manages:\n",
    "- **Batching** → groups samples into batches\n",
    "- **Shuffling** → randomizes data order between epochs\n",
    "- **Parallel loading** → uses multiple workers for faster data loading\n",
    "\n",
    "### Important Note\n",
    "\n",
    "The DataLoader does not store data itself. It only knows how to iterate over the Dataset efficiently.\n",
    "\n",
    "---\n",
    "\n",
    "## DataLoader Control Flow\n",
    "\n",
    "Understanding how the DataLoader operates during training is crucial:\n",
    "\n",
    "### At the Start of Each Epoch\n",
    "\n",
    "1. **Shuffling** (if `shuffle=True`)\n",
    "   - The DataLoader shuffles indices using a sampler\n",
    "\n",
    "2. **Index Division**\n",
    "   - Divides indices into chunks of `batch_size`\n",
    "\n",
    "3. **Data Fetching**\n",
    "   - For each index in the chunk, data samples are fetched from the Dataset object\n",
    "\n",
    "4. **Batch Creation**\n",
    "   - The samples are collected and combined into a batch (using `collate_fn`)\n",
    "\n",
    "5. **Batch Return**\n",
    "   - The batch is returned to the main training loop\n",
    "\n",
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "| Aspect | Dataset | DataLoader |\n",
    "|--------|---------|------------|\n",
    "| **Purpose** | Defines how to access individual samples | Manages efficient iteration over the Dataset |\n",
    "| **Batching** | No | Yes |\n",
    "| **Shuffling** | No | Yes (optional) |\n",
    "| **Parallel Loading** | No | Yes (optional) |\n",
    "| **Returns** | Single sample | Batch of samples |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cdd79d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, feature, label):\n",
    "        self.feature = feature\n",
    "        self.label = label\n",
    "    def __len__(self):\n",
    "        return len(self.feature)\n",
    "    def __getitem__(self, index):\n",
    "        return self.feature[index], self.label[index]\n",
    "    \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dbad2365",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = CustomDataset(X_test_tensor, y_test_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "73d9ec2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 1.7364, -1.1408,  1.7569,  1.8031,  0.2635,  0.5090,  1.3539,  1.4126,\n",
       "         -0.0311, -0.5802,  1.1816, -0.8040,  1.1802,  1.0927,  1.3899, -0.0560,\n",
       "          0.8691,  1.1091, -0.3611,  0.4739,  1.2873, -1.4481,  1.3200,  1.2027,\n",
       "          0.2083, -0.3229,  0.6282,  0.7200, -0.8715, -0.4013]),\n",
       " tensor(1.))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cddd3c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2f596917",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class MySimpleNN(nn.Module):\n",
    "\n",
    "  def __init__(self, num_features):\n",
    "\n",
    "    super().__init__()\n",
    "    self.linear = nn.Linear(num_features, 1)\n",
    "    self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "  def forward(self, features):\n",
    "\n",
    "    out = self.linear(features)\n",
    "    out = self.sigmoid(out)\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3ddd929d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "learning_rate = 0.1\n",
    "epochs = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1ab1a648",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "model = MySimpleNN(X_train_tensor.shape[1])\n",
    "\n",
    "# define optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# define loss function\n",
    "loss_function = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b3dfb423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 0.16715478897094727\n",
      "Epoch: 2, Loss: 0.20528551936149597\n",
      "Epoch: 3, Loss: 0.07430488616228104\n",
      "Epoch: 4, Loss: 0.05409431830048561\n",
      "Epoch: 5, Loss: 0.06697890162467957\n",
      "Epoch: 6, Loss: 0.02887369878590107\n",
      "Epoch: 7, Loss: 0.11894514411687851\n",
      "Epoch: 8, Loss: 0.07590161263942719\n",
      "Epoch: 9, Loss: 0.31549009680747986\n",
      "Epoch: 10, Loss: 0.16598443686962128\n",
      "Epoch: 11, Loss: 0.16959115862846375\n",
      "Epoch: 12, Loss: 0.017913049086928368\n",
      "Epoch: 13, Loss: 0.6652785539627075\n",
      "Epoch: 14, Loss: 0.06324651092290878\n",
      "Epoch: 15, Loss: 0.07599916309118271\n",
      "Epoch: 16, Loss: 0.1870088130235672\n",
      "Epoch: 17, Loss: 0.07651824504137039\n",
      "Epoch: 18, Loss: 0.3982279896736145\n",
      "Epoch: 19, Loss: 0.4466966986656189\n",
      "Epoch: 20, Loss: 0.052366580814123154\n",
      "Epoch: 21, Loss: 0.1174897775053978\n",
      "Epoch: 22, Loss: 0.34110626578330994\n",
      "Epoch: 23, Loss: 0.03582226485013962\n",
      "Epoch: 24, Loss: 0.00600298959761858\n",
      "Epoch: 25, Loss: 0.07786466926336288\n"
     ]
    }
   ],
   "source": [
    "## Training pipeline\n",
    "\n",
    "# define loop\n",
    "for epoch in range(epochs):\n",
    "\n",
    "  for batch_features, batch_labels in train_loader:\n",
    "\n",
    "    # forward pass\n",
    "    y_pred = model(batch_features)\n",
    "\n",
    "    # loss calculate\n",
    "    loss = loss_function(y_pred, batch_labels.view(-1,1))\n",
    "\n",
    "    # clear gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # backward pass\n",
    "    loss.backward()\n",
    "\n",
    "    # parameters update\n",
    "    optimizer.step()\n",
    "\n",
    "  # print loss in each epoch\n",
    "  print(f'Epoch: {epoch + 1}, Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "41d253e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9688\n"
     ]
    }
   ],
   "source": [
    "## Evaluation\n",
    "# Model evaluation using test_loader\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "accuracy_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_features, batch_labels in test_loader:\n",
    "        # Forward pass\n",
    "        y_pred = model(batch_features)\n",
    "        y_pred = (y_pred > 0.8).float()  # Convert probabilities to binary predictions\n",
    "\n",
    "        # Calculate accuracy for the current batch\n",
    "        batch_accuracy = (y_pred.view(-1) == batch_labels).float().mean().item()\n",
    "        accuracy_list.append(batch_accuracy)\n",
    "\n",
    "# Calculate overall accuracy\n",
    "overall_accuracy = sum(accuracy_list) / len(accuracy_list)\n",
    "print(f'Accuracy: {overall_accuracy:.4f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
